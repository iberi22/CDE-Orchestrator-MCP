# src/mcp_tools/git_analysis.py
"""
Professional Git Analysis MCP Tool.

Provides comprehensive Git repository analysis using Rust-accelerated parallel processing:
- Complete commit history with parallel extraction
- Branch analysis (active, stale, merged)
- Contributor insights (commits, impact, code churn)
- Code hotspots (most changed files)
- Development patterns (frequency, peak times)
- Architectural decisions (refactoring, migrations)
- Release patterns (tags, versioning)
"""

import json
import logging
import os
from typing import Optional

from fastmcp import Context

from ._base import tool_handler
from ._progress_reporter import get_progress_reporter

logger = logging.getLogger(__name__)

# Try to import Rust module for accelerated Git analysis
try:
    from cde_rust_core import analyze_git_repository_py

    RUST_GIT_AVAILABLE = True
except ImportError:
    RUST_GIT_AVAILABLE = False
    logger.warning("Rust Git analyzer not available, using Python fallback")


@tool_handler
async def cde_analyzeGit(
    ctx: Context,
    project_path: str = ".",
    days: int = 90,
    include_all_branches: bool = False,
) -> str:
    """
    ğŸ” **Professional Git Analysis** - Comprehensive repository analysis with Rust acceleration.

    Analyzes Git repository to provide deep insights for project context:
    - **Commit History**: Recent commits with stats (parallel extraction)
    - **Branch Analysis**: Active, stale, and merged branches
    - **Contributors**: Team members with impact scores
    - **Code Churn**: Most changed files (hotspots)
    - **Development Patterns**: Commit frequency, peak times
    - **Architectural Decisions**: Refactoring, migrations detected
    - **Release Patterns**: Tags, versioning, release frequency

    **Performance**:
    - Uses Rust + Rayon for parallel processing (12+ threads)
    - 10-100x faster than Python-only Git analysis
    - Handles large repositories (100k+ commits)

    **Args**:
        project_path: Path to project (default: current directory)
        days: Number of days to analyze (default: 90)
        include_all_branches: Analyze all branches, not just current (default: False)

    **Returns**:
        JSON with comprehensive Git analysis:
        - repository_info: Basic repository metadata
        - commit_history: Recent commits with stats
        - branch_analysis: Active/stale branches
        - contributor_insights: Team activity and impact
        - code_churn: Most changed files
        - development_patterns: Commit frequency analysis
        - architectural_decisions: Detected refactoring/migrations
        - release_patterns: Tag/release frequency

    **Examples**:
        >>> cde_analyzeGit()  # Analyze current project, last 90 days
        >>> cde_analyzeGit(days=30)  # Last 30 days
        >>> cde_analyzeGit(project_path="E:\\my-project", days=180)  # 6 months

    **Use Cases**:
        1. **Onboarding**: Understand project history and team dynamics
        2. **Health Check**: Identify development patterns and bottlenecks
        3. **Code Review**: Find hotspots that need refactoring
        4. **Team Analysis**: Understand contributor impact and activity
        5. **Release Planning**: Analyze release frequency and patterns

    **Integration**:
        - Used by `cde_onboardingProject` for enriched context
        - Complements `cde_scanDocumentation` and `cde_setupProject`
        - Provides data for AI assistant configuration
    """
    reporter = get_progress_reporter()
    reporter.reset()
    reporter.report_progress("CDE", "analyzeGit", 0.1, "Initializing Git analysis...")

    if project_path == ".":
        project_path = os.getcwd()

    reporter.report_progress(
        "CDE", "analyzeGit", 0.3, f"Analyzing Git repository at {project_path}..."
    )

    try:
        if RUST_GIT_AVAILABLE:
            # Use Rust-accelerated analysis (10-100x faster)
            logger.info("Using Rust-accelerated Git analysis")
            reporter.report_progress(
                "CDE",
                "analyzeGit",
                0.5,
                "Extracting Git data (Rust parallel processing)...",
            )

            analysis_json = analyze_git_repository_py(project_path, days)
            analysis = json.loads(analysis_json)

            reporter.report_progress(
                "CDE", "analyzeGit", 0.9, "Formatting analysis results..."
            )

        else:
            # Fallback to Python implementation
            logger.info("Using Python fallback for Git analysis")
            reporter.report_progress(
                "CDE", "analyzeGit", 0.5, "Extracting Git data (Python fallback)..."
            )

            analysis = await _analyze_git_python_fallback(project_path, days)

        # Enrich analysis with summary
        analysis["analysis_summary"] = _generate_summary(analysis)

        reporter.report_progress("CDE", "analyzeGit", 1.0, "Git analysis complete")

        return json.dumps(analysis, indent=2)

    except Exception as e:
        logger.error(f"Git analysis failed: {e}")
        return json.dumps(
            {
                "status": "error",
                "error": str(e),
                "message": "Git analysis failed. Ensure project is a Git repository.",
            },
            indent=2,
        )


async def _analyze_git_python_fallback(
    project_path: str, days: int
) -> dict:
    """
    Fallback Git analysis using Python GitPython library.

    Slower than Rust but provides basic functionality when Rust module unavailable.
    """
    try:
        from git import Repo

        repo = Repo(project_path)

        # Basic analysis
        commits = list(repo.iter_commits(max_count=50))
        branches = [b.name for b in repo.branches]

        commit_info = []
        for commit in commits:
            commit_info.append(
                {
                    "hash": commit.hexsha[:8],
                    "author": str(commit.author),
                    "email": commit.author.email,
                    "date": commit.committed_datetime.isoformat(),
                    "message": commit.message.split("\n")[0],
                    "files_changed": len(commit.stats.files),
                    "insertions": commit.stats.total["insertions"],
                    "deletions": commit.stats.total["deletions"],
                }
            )

        return {
            "repository_info": {
                "path": project_path,
                "total_commits": len(list(repo.iter_commits())),
                "total_branches": len(branches),
            },
            "commit_history": {"recent_commits": commit_info},
            "branch_analysis": {"branches": branches},
            "note": "Using Python fallback (slower). Install Rust module for 10-100x speedup.",
        }

    except ImportError:
        return {
            "status": "error",
            "error": "GitPython not available",
            "message": "Install GitPython: pip install gitpython",
        }
    except Exception as e:
        return {"status": "error", "error": str(e)}


def _generate_summary(analysis: dict) -> dict:
    """Generate human-readable summary of Git analysis."""

    repo_info = analysis.get("repository_info", {})
    commit_history = analysis.get("commit_history", {})
    contributors = analysis.get("contributor_insights", [])
    code_churn = analysis.get("code_churn", {})
    dev_patterns = analysis.get("development_patterns", {})

    # Generate insights
    insights = []

    # Repository age
    age_days = repo_info.get("repository_age_days", 0)
    if age_days > 365:
        insights.append(
            f"ğŸ‚ Mature project ({age_days // 365} years old, {repo_info.get('total_commits', 0)} commits)"
        )
    elif age_days > 90:
        insights.append(
            f"ğŸ“… Established project ({age_days} days old, {repo_info.get('total_commits', 0)} commits)"
        )
    else:
        insights.append(
            f"ğŸŒ± New project ({age_days} days old, {repo_info.get('total_commits', 0)} commits)"
        )

    # Development activity
    frequency = dev_patterns.get("commit_frequency", "Unknown")
    avg_commits = commit_history.get("average_commits_per_week", 0)
    insights.append(
        f"ğŸ“ˆ Development: {frequency} ({avg_commits:.1f} commits/week average)"
    )

    # Team size
    if contributors:
        insights.append(f"ğŸ‘¥ Team: {len(contributors)} active contributors")
        top_contributor = max(contributors, key=lambda c: c.get("total_commits", 0))
        insights.append(
            f"â­ Top contributor: {top_contributor.get('name')} ({top_contributor.get('total_commits')} commits)"
        )

    # Code hotspots
    hotspots = code_churn.get("hotspots", [])
    if hotspots:
        insights.append(f"ğŸ”¥ Code hotspots detected: {len(hotspots)} files")
        insights.append(f"   Most changed: {hotspots[0] if hotspots else 'N/A'}")

    # Architectural decisions
    arch_decisions = analysis.get("architectural_decisions", [])
    if arch_decisions:
        insights.append(
            f"ğŸ—ï¸ Architectural decisions: {len(arch_decisions)} refactorings/migrations detected"
        )

    return {
        "insights": insights,
        "key_metrics": {
            "age_days": age_days,
            "total_commits": repo_info.get("total_commits", 0),
            "contributors": len(contributors),
            "hotspots": len(hotspots),
            "architectural_changes": len(arch_decisions),
        },
    }
