---
title: "AWS Bedrock + Claude Agent Integration Strategy"
description: "Three architectures for integrating AWS Bedrock (Claude Sonnet 4.5) with CLI agents for CDE-Orchestrator-MCP"
type: "design"
status: "active"
created: "2025-11-02"
updated: "2025-11-02"
author: "Architecture Team"
llm_summary: |
  Evaluates three strategies for CLI agent integration with AWS Bedrock + Claude Sonnet 4.5:
  (1) Aider with native Bedrock support, (2) LiteLLM proxy server with OpenAI-compatible API,
  (3) Custom CLI agent via Anthropic SDK. Includes comparative matrix, recommendations, and implementation roadmap.
---

# AWS Bedrock + Claude Agent Integration Strategy

## Executive Summary

This document evaluates **three distinct architectures** for building a robust CLI agent that abstracts AWS Bedrock (Claude Sonnet 4.5) behind a simple, production-ready interface suitable for the **CDE-Orchestrator-MCP** project.

**Problem**: Users need an intelligent CLI agent that can work with AWS Bedrock's Claude Sonnet 4.5 model, either through direct access or via a proxy that "masks" the Bedrock service details.

**Solution**: Three viable architectures, ranked by **production-readiness**, **maintenance burden**, and **feature completeness**.

---

## Architecture Overview

### Strategy 1: Aider (Direct Bedrock Integration) ðŸ¥‡ RECOMMENDED

**Summary**: Use [Aider](https://github.com/aider-ai/aider) CLI agent with native AWS Bedrock support.

**Status**: âœ… **PRODUCTION-READY** (38.2k GitHub stars, 163 contributors, mature codebase)

#### Key Facts

- **Bedrock Support**: âœ… Native support documented at [aider.chat/docs/llms/bedrock.html](https://aider.chat/docs/llms/bedrock.html)
- **Model Support**: âœ… Claude 3.7 Sonnet listed as **best model for Aider**
- **Features**:
  - Multi-file code editing with git integration
  - Automatic commit messages with sensible context
  - Codebase mapping for large projects
  - 100+ language support
  - Voice-to-code capability
  - Linting & testing integration

#### Implementation: Bedrock Configuration

```bash
# Install Aider
pip install aider-chat

# Configure AWS credentials
export AWS_REGION=us-east-1
export AWS_PROFILE=bedrock  # Uses ~/.aws/credentials

# Use with Bedrock
aider --model bedrock/anthropic.claude-3-sonnet-20240229-v1:0

# Or directly in code
aider --model bedrock/anthropic.claude-sonnet-4-5-20250929-v1:0 /path/to/project
```

#### Pros âœ…

1. **Zero maintenance**: Community-maintained, active development
2. **Native Bedrock support**: No proxy layer needed
3. **Feature-rich**: Designed for real coding workflows
4. **Proven in production**: Used by 557+ projects
5. **Git-aware**: Auto-commits with context
6. **Multi-language**: Works with Python, JavaScript, Rust, Go, etc.
7. **Extensible**: Can be scripted or integrated via Python API

#### Cons âŒ

1. **Requires Git repo**: Must work within a git repository
2. **Interactive by default**: Prompts user for confirmation (mitigated by `--yes` flag)
3. **External dependency**: Relies on Aider project roadmap
4. **Not designed as library**: Primarily CLI tool (SDK possible but not primary design)

#### Use Case

âœ… **Best for**: Existing code repositories, iterative development, team coding sessions
âŒ **Not ideal for**: Stateless code generation (but workaround exists)

---

### Strategy 2: LiteLLM Proxy Server ðŸ¥ˆ ENTERPRISE OPTION

**Summary**: Deploy LiteLLM proxy server that translates OpenAI-compatible API calls to AWS Bedrock.

**Status**: âœ… **PRODUCTION-READY** (30.6k GitHub stars, 968 contributors, Y Combinator W23)

#### Key Facts

- **Bedrock Support**: âœ… Full support for all Bedrock models including Claude Sonnet
- **OpenAI Compatibility**: âœ… Exposes `/chat/completions` endpoint
- **LiteLLM Model**: `bedrock/anthropic.claude-sonnet-4-5-20250929-v1:0`
- **Proxy Capabilities**: Cost tracking, rate limiting, load balancing, auth hooks

#### Implementation: Quick Start

```bash
# Install LiteLLM with proxy support
pip install 'litellm[proxy]'

# Create config.yaml
cat > config.yaml << 'EOF'
model_list:
  - model_name: bedrock-claude-sonnet
    litellm_params:
      model: bedrock/anthropic.claude-sonnet-4-5-20250929-v1:0
      aws_region: us-east-1
      aws_profile: bedrock
EOF

# Start proxy server
litellm --config config.yaml

# Now use OpenAI-compatible clients
curl http://localhost:4000/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "bedrock-claude-sonnet",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

#### OpenAI SDK Integration

```python
from openai import OpenAI

client = OpenAI(
    api_key="sk-anything",  # Not used, local proxy
    base_url="http://localhost:4000"
)

response = client.chat.completions.create(
    model="bedrock-claude-sonnet",
    messages=[{"role": "user", "content": "Write Python code to..."}]
)
```

#### Pros âœ…

1. **Abstraction layer**: Any OpenAI-compatible tool now works with Bedrock
2. **Cost tracking**: Built-in spend monitoring per project/API key
3. **Rate limiting**: Prevent runaway costs
4. **Load balancing**: Route across multiple models/regions
5. **Enterprise features**: User management, logging, analytics
6. **Stateless**: Easy to horizontally scale
7. **Works with Aider**: Aider supports OpenAI-compatible APIs

#### Cons âŒ

1. **Network overhead**: Additional hop for each request
2. **Operational burden**: Must manage proxy server (though containerized)
3. **Latency**: Extra milliseconds for proxy translation
4. **Debugging**: One more layer to troubleshoot
5. **Complexity**: More setup than direct Bedrock

#### Use Case

âœ… **Best for**: Multi-tenant systems, cost control, using multiple models, enterprise deployments
âŒ **Not ideal for**: Single-developer, low-latency scenarios

---

### Strategy 3: Custom CLI Agent (Anthropic SDK) ðŸ¥‰ CONTROL OPTION

**Summary**: Build custom CLI agent directly using Anthropic's Python SDK with Bedrock backend.

**Status**: âš ï¸ **REQUIRES DEVELOPMENT** (but fully achievable)

#### Implementation: Lightweight Agent

```python
#!/usr/bin/env python3
"""
cde-agent: CLI agent for CDE-Orchestrator-MCP with AWS Bedrock
"""

from anthropic import AnthropicBedrock
from pathlib import Path
import json
import sys

def create_bedrock_client():
    """Initialize Bedrock client (uses AWS credentials from environment)"""
    return AnthropicBedrock(
        aws_region="us-east-1",
        aws_profile="bedrock"
    )

def execute_task(prompt: str, project_path: str = "."):
    """Execute a development task with Claude Sonnet via Bedrock"""
    client = create_bedrock_client()

    # Read project context (optional)
    context = read_project_structure(project_path)

    # Build system prompt
    system = """You are an expert software engineer assistant.
You help with:
- Writing and refactoring code
- Analyzing bugs
- Creating tests
- Documentation
- Architecture design

Always provide clear, production-ready code.
When modifying files, explain the changes."""

    # Create message
    response = client.messages.create(
        model="anthropic.claude-sonnet-4-5-20250929-v1:0",
        max_tokens=4096,
        system=system,
        messages=[
            {
                "role": "user",
                "content": f"Project context:\n{context}\n\nTask: {prompt}"
            }
        ]
    )

    return response.content[0].text

def read_project_structure(path: str) -> str:
    """Scan and return project structure for context"""
    root = Path(path)
    files = []

    # Scan up to 10 key files
    for ext in ['*.py', '*.md', '*.json', '*.yaml']:
        for f in root.rglob(ext):
            if '.git' not in f.parts and '__pycache__' not in f.parts:
                files.append(str(f.relative_to(root)))
                if len(files) >= 10:
                    break

    return f"Project files: {', '.join(files)}"

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: cde-agent '<prompt>' [project_path]")
        sys.exit(1)

    prompt = sys.argv[1]
    project_path = sys.argv[2] if len(sys.argv) > 2 else "."

    result = execute_task(prompt, project_path)
    print(result)
```

#### Installation & Usage

```bash
# Install
pip install anthropic boto3

# Configure AWS
export AWS_REGION=us-east-1
export AWS_PROFILE=bedrock

# Use
cde-agent "Add error handling to this function" src/

# With file editing (advanced)
cde-agent "Create a test file for user authentication"
```

#### Pros âœ…

1. **Full control**: Customize every behavior
2. **No dependencies**: Pure Anthropic SDK + boto3
3. **Lightweight**: Minimal overhead
4. **Direct Bedrock**: No proxy, lowest latency
5. **Tailored UX**: Design exactly for your workflow

#### Cons âŒ

1. **Development required**: Must build file editing, git integration, multi-file handling
2. **Maintenance burden**: You own all features (no community)
3. **Feature creep**: Risk of reinventing Aider
4. **Testing**: Significant QA effort
5. **Competitive disadvantage**: Aider already solved these problems

#### Use Case

âœ… **Best for**: Learning, prototyping, deeply specialized workflows
âŒ **Not ideal for**: Production use (Aider already does this better)

---

## Comparative Matrix

| Feature | Aider (Direct) | LiteLLM (Proxy) | Custom SDK |
|---------|---|---|---|
| **Production Ready** | âœ… Yes | âœ… Yes | âš ï¸ Requires build |
| **Setup Time** | 5 min | 15 min | 2-3 days |
| **Maintenance** | Community | Community | Self |
| **Bedrock Native** | âœ… Yes | âœ… Yes | âœ… Yes |
| **Multi-file Editing** | âœ… Built-in | âš ï¸ Via integrations | âŒ Build yourself |
| **Git Integration** | âœ… Native | âš ï¸ Possible | âŒ Manual |
| **Cost Tracking** | âŒ No | âœ… Yes | âŒ Manual |
| **Load Balancing** | âŒ No | âœ… Yes | âŒ No |
| **API Compatibility** | CLI | OpenAI-compatible | Bedrock-only |
| **Latency** | ~100ms | ~150ms | ~100ms |
| **Scalability** | Single process | Horizontal | Single process |

---

## Recommendation: ðŸ¥‡ Aider (Direct Bedrock)

### Why Aider Wins

1. **Fastest to production**: Install â†’ Configure AWS â†’ Go
2. **Proven in production**: 38k stars, real teams using it daily
3. **Native Bedrock support**: Zero translation overhead
4. **Best for code tasks**: Aider literally built for this use case
5. **Lower maintenance**: Delegate to active community
6. **Zero reinvention**: Don't rebuild what already exists

### Implementation Path (Next 48 hours)

1. **Hour 1**: Update `setup-aws-bedrock.ps1` to install Aider
2. **Hour 2**: Create wrapper script `cde-agent` that invokes Aider with Bedrock config
3. **Hour 4**: Write integration tests with real Bedrock calls
4. **Hour 6**: Document usage patterns for CDE-Orchestrator-MCP
5. **Hour 8**: Create MCP tool `cde_startCodingSession` that launches Aider

### When to Reconsider

- âŒ **If you need stateless code generation**: Aider isn't designed for that (though `--yes` helps)
- âŒ **If you need cost tracking per project**: Use LiteLLM instead
- âŒ **If you need HTTP API**: Use LiteLLM proxy
- âœ… **If you want the best code editing experience**: Aider

---

## Integration with CDE-Orchestrator-MCP

### Phase 1: Core Integration (Week 1)

Create MCP tool that launches Aider session:

```python
@server.call_tool()
async def handle_start_coding_session(arguments: dict):
    """
    Start Aider coding session with Bedrock + Sonnet

    Args:
        prompt: User's coding request
        project_path: Path to project repository
        auto_yes: Skip confirmation prompts (default: False)
    """
    prompt = arguments.get("prompt")
    project_path = arguments.get("project_path", ".")
    auto_yes = arguments.get("auto_yes", False)

    # Start Aider session
    cmd = [
        "aider",
        "--model", "bedrock/anthropic.claude-sonnet-4-5-20250929-v1:0",
        project_path
    ]

    if auto_yes:
        cmd.append("--yes")

    # Additional context
    initial_message = f"Request: {prompt}"

    return {
        "status": "session_started",
        "command": " ".join(cmd),
        "instructions": f"Aider will now help with: {prompt}"
    }
```

### Phase 2: Advanced Integration (Week 2-3)

- Integrate with MCP workflow engine
- Add session history tracking
- Create skill modules for Aider (custom prompt templates)
- Build dashboard showing active sessions

---

## Deployment Considerations

### AWS IAM Permissions Required

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "bedrock:InvokeModel",
        "bedrock:InvokeModelWithResponseStream"
      ],
      "Resource": "arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-sonnet-4-5-20250929-v1:0"
    }
  ]
}
```

### Docker Deployment

```dockerfile
FROM python:3.12-slim

WORKDIR /app

# Install Aider and dependencies
RUN pip install aider-chat anthropic boto3

# Configure AWS credentials (via env vars or volume mount)
ENV AWS_REGION=us-east-1

# Create entrypoint
COPY cde-agent.py /app/cde-agent

ENTRYPOINT ["/app/cde-agent"]
```

---

## Risk Analysis

### Aider Risks

| Risk | Likelihood | Impact | Mitigation |
|------|-----------|--------|-----------|
| Aider drops Bedrock support | Low | High | Fallback to LiteLLM proxy |
| Git operations fail | Medium | Medium | Wrapper handles git errors |
| Bedrock API changes | Low | Medium | AWS maintains API stability |

### Mitigation Strategy

1. **Version pinning**: Lock Aider version in requirements.txt
2. **Fallback proxy**: Keep LiteLLM proxy config ready
3. **Session backups**: Auto-save session context before/after
4. **Monitoring**: Track Bedrock API errors

---

## Next Steps

1. âœ… **Validate Aider + Bedrock integration** (run proof-of-concept)
2. âœ… **Update setup scripts** to install Aider
3. âœ… **Create wrapper CLI** for CDE-Orchestrator-MCP
4. âœ… **Write integration tests**
5. âœ… **Document for team**

---

## Appendix: Testing the Integration

```bash
# 1. Setup AWS credentials
export AWS_REGION=us-east-1
export AWS_PROFILE=bedrock

# 2. Install Aider
pip install aider-chat

# 3. Test with a simple project
mkdir test-project && cd test-project
git init
echo "print('hello')" > hello.py
git add . && git commit -m "initial"

# 4. Start Aider session
aider --model bedrock/anthropic.claude-sonnet-4-5-20250929-v1:0

# 5. In Aider prompt:
# > Add a function that doubles the input number

# 6. Verify Bedrock was called (check boto3 logs)
# SUCCESS: File edited, git commit created
```

---

**Document Version**: 1.0
**Last Updated**: 2025-11-02
**Author**: CDE Architecture Team
**Status**: READY FOR IMPLEMENTATION
